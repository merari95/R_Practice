---
title: "DSCI 523 Lab 2"
subtitle: "Working with dates, strings & factors, two-table joins, and base R control flow"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lab Mechanics
rubric={mechanics:5}

- All files necessary to run your work must be pushed to your GitHub.ubc.ca repository for this lab.
- You need to have a minimum of 3 commit messages associated with your GitHub.ubc.ca repository for this lab.
- You must also submit `.Rmd` file and the rendered pdf in this worksheet/lab to Gradescope. Entire notebook must be executed so the TA's can see the results of your work. 
- **There is autograding in this lab, so please do not move or rename this file. Also, do not copy and paste cells, if you need to add new cells, create new cells via the "Insert a cell below" button instead.**
- To ensure you do not break the autograder remove all code for installing packages (i.e., DO NOT have `install.packages(...)` or `devtools::install_github(...)` in your homework!
- Follow the [MDS general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).
- <mark>This lab has hidden tests. In this lab, the visible tests are just there to ensure you create an object with the correct name. The remaining tests are hidden intentionally. This is so you get practice deciding when you have written the correct code and created the correct data object. This is a necessary skill for data scientists, and if we were to provide robust visible tests for all questions you would not develop this skill, or at least not to its full potential.</mark>

## Code Quality
rubric={quality:5}

The code that you write for this assignment will be given one overall grade for code quality, see our code quality rubric as a guide to what we are looking for. Also, for this course (and other MDS courses that use R), we are trying to follow the tidyverse code style. There is a guide you can refer too: http://style.tidyverse.org/

Each code question will also be assessed for code accuracy (i.e., does it do what it is supposed to do?).

## Writing 
rubric={writing:5}

To get the marks for this writing component, you should:

- Use proper English, spelling, and grammar throughout your submission (the non-coding parts).
- Be succinct. This means being specific about what you want to communicate, without being superfluous.

## Let's get started!

Run the cell below to load the libraries needed for this lab, as well as the test file so you can check your answers as you go!

```{r}
library(gapminder)
library(lubridate)
library(testthat)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
```

> Note - there is an issue with loading packages with `tidyverse` and the autograding software we are using.
Thus, for assignments, please load the packages individually as I have done above instead of loading them via the tidyverse.

## Exercise 1: Working with dates
rubric={autograde:15}

In our recent past, we experienced the COVID-19 global pandemic. 
With your new data science skills, 
you can start to look at and visualize the data 
about this impactful pandemic yourself. 
Let's look at cumulative confirmed cases in British Columbia 
over a 3 month period from 2021/06/10 to 2021/09/10 
(it was a peak COVID season then). 
We can obtain such data from the 
[COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19).

In particular, 
use R to load the `time_series_covid19_confirmed_global.csv` file 
located at the url: 
[https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv](https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv).

Then you will need to filter this global data set for records 
from the province of British Columbia 
during the time interval 2021/06/10 to 2021/09/10. 
Note that, you might need to tidy the data before you filter the time interval.
Following this question, we provide you data visualization code. 
However your task is to ensure the dataframe is suitable for visualization.

The final data set for data visualization 
should be named `bc_covid19_confirmed_3_months` 
and have only the following two columns: 

- one named `date`, which should be of class "Date"
- one named `confirmed_cases`, which should of class "numeric" (and type "double")

```{r tags=c()}
url <- "https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
time_series_covid19_confirmed_global <- NULL
# create a time interval that you want to calculate
three_months <- NULL

bc_covid19_confirmed_3_months <- NULL

bc_covid19_confirmed_3_months
```

```{r}
. = ottr::check("tests/e1.R")
```

Let's now visualize how cases have changed over those three months in British Columbia by viewing cumulative cases per day:

```{r}
three_months_BC <- ggplot(bc_covid19_confirmed_3_months, 
                          aes(x = date, y = confirmed_cases)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  xlab("2021") + 
  ylab("Cumulative COVID-19 cases") +
  ggtitle("BC COVID-19 cases started to increase more rapidly in August and September of 2021") +
  theme_bw()

three_months_BC
```

## Exercise 2: Working with strings

rubric={accuracy:20}

You have learned about string operations combined with regular expressions.    

  * Pattern matching with `str_match()`   
  * String replacement with `str_replace()` etc.    
  * String splitting with `str_split()` etc.    

Now you are ready to apply them to the real world of data cleaning!    

In this exercise, you will start with the dirty version of `Gapminder` in our course repository, [gapminderDataFiveYear_dirty.txt](https://github.com/STAT545-UBC/STAT545-UBC.github.io/blob/master/gapminderDataFiveYear_dirty.txt) (use ```read_tsv``` to read it), and clean it up with all the string functions you've learned. The goal of this exercise is to use R code to clean up the dirty `gapminder` to the point that it's identical to the clean `gapminder`.  Remember that in R, to define a single backslash in a regex expression, you should use two backslahses in your expression (`\\`), you can read more about why [here](https://cran.r-project.org/web/packages/stringr/vignettes/regular-expressions.html#escaping). 

To help you, we will provide you with some useful code to help you test whether your cleaned-up dirty Gapminder is the same as the clean gapminder data set from the gapminder R package. Also, [this blog post on how to compare data frames](https://sharla.party/post/comparing-two-dfs/) could be really helpful in completing your task.

Things you might want to do to clean up `gapminderDataFiveYear_dirty.txt`:

- check if the data is tidy (it should have the same variables as `gapminder::gapminder`;
- check if there is any missing data, if there is missing data fill it in with sensible values if possible;
- check that all values match those in `gapminder::gapminder` (e.g., check capitalization, spelling, grammar, etc);
- make sure the columns are the same types as `gapminder::gapminder`.

```{r tags=c()}

```

```{r}
test_that("dirty_gap is not the same as gapminder", {
  expect_equal(dirty_gap, gapminder)
})
```

## Exercise 3: Taking control of your factors
rubric={accuracy:7,reasoning:8}

Explore the effects of the `dplyr` `arrange` function. 
Does arranging the data have any effect on, say, a figure? 
What about the `forcats` 
[`fct_rev`](https://forcats.tidyverse.org/reference/fct_rev.html), 
`fct_relevel`, or `fct_reorder` functions? 
This exploration must involve the data, the factor levels, 
and some figures, 
as well as a written explanation of what you are doing and what you find. 
Choose any data set you wish to demonstrate this. 
We provide code for a scatter plot figure, 
which you could modify for your data set to help you out. 
*Note: you only need to explore one `forcats` function here.*

```{r}
# sample plot code you can modify
library(palmerpenguins)

options(repr.plot.width = 7, repr.plot.height = 5)
penguins_original <- ggplot(data = penguins, mapping = aes(x = bill_length_mm, 
                                      y = body_mass_g,
                                     colour = species)) +
    geom_point(size = 2) +
    xlab("Bill length (mm)") +
    ylab("Body mass (g)") +
    theme_bw() +
    theme(text = element_text(size = 18))
penguins_original
```

_Type your answer here, replacing this text._

```{r tags=c()}

```

## Exercise 4: Two table joins cheatsheet
rubric={accuracy:7,reasoning:8} 

This exercise is to help you familiarize with the different _joins_ available in `dplyr`. First, take a look at [Jenny Bryan's cheatsheet](http://stat545.com/bit001_dplyr-cheatsheet.html). Your task is to create your own cheatsheet, covering all the joins that Jenny covers (and in both orders for joins where order has an effect), but focused on something you care about. Examples:

  - Pets I have owned + breed + friendly vs. unfriendly + ??. Join to a table of pet breed, including variables for furry vs not furry, mammal true or false, etc.
  - Movies and studios....
  - Athletes and teams....

The data set should be tractable (think 5-7 items in each table). **You are expected to create your own data set for this question, do not use an existing data set.**|

While demonstrating the joins with your data and code, also provide a narrative in written English explaining what you are doing and what is revealed through the joins. The narrative should be ~ 2-4 sentences per join scenario. **This narrative must be in your own words**.

You will likely need to iterate between your data prep and your joining to make your explorations comprehensive and interesting. For example, you will want a specific amount (or lack) of overlap between the two data frames, in order to demonstrate all the different joins. You will want both the data frames to be as small as possible, while still retaining the expository value.

You should create this cheatsheet as a separate `.Rmd` file that you render to `.md` (you can do that by setting `output: github_document` at the top of your `.Rmd` file). Both of these files should live in this lab2 repo, and you should paste the links (URL) to them below:

_Type your answer here, replacing this text._

## Exercise 5: Control flow with base R
rubric={accuracy:15}

There was a major (> 8,600 acres) wildfire (named the El Dorado fire) that started on Saturday, September 5, 2020 in San Bernardino County which blame has been assigned to the use of a smoke-generating pyrotechnic device at a gender reveal party (Source: https://www.cbc.ca/news/world/califoronia-wildfires-september-7-gender-reveal-party-1.5714719). 

> <img src="https://i.cbc.ca/1.5715027.1599506927!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/california-wildfires.jpg" width=300>
>
> *A firefighter battles the Creek Fire as it threatens homes in the Cascadel Woods neighborhood of Madera County, Calif., on Monday, Sept. 7, 2020. (Noah Berger/The Associated Press)*

Below we give you two ordered lists, the first contains the air quality index (AQI) values, the daily reported measured values of AQI, for the area of Los Angeles-Long Beach-Anaheim, California, USA for 18 days. This is the closest major city to the El Dorado fire. The second ordered list contains the dates for each measurement. Data source: https://www.epa.gov/outdoor-air-quality-data/air-data-daily-air-quality-tracker

Your task is to use base R control flow (specifically `for` loops and `if`/`else` statements) to calculate the average of the maximum daily AQI measurements, before the fire began, and afterwards. Use a `print` statement to output your results in a sentence that communicates your findings. *Hint: `paste` will be a useful function for this.* 

Note: treat the AQI from 2020-09-05 (the day the fire started) in the group after the fire.

```{r tags=c()}
aqi <- list(165, 179, 199, 136, 91, 121, 161, 78, 84,
               80, 73, 55, 57, 55, 55, 55, 62, 68)
date <- list("2020-09-13", "2020-09-12", "2020-09-11",
             "2020-09-10", "2020-09-09", "2020-09-08", 
             "2020-09-07", "2020-09-06", "2020-09-05",
             "2020-09-04", "2020-09-03", "2020-09-02", 
             "2020-09-01", "2020-08-31", "2020-08-30",
             "2020-08-29", "2020-08-28", "2020-08-27")
```

## Exercise 6: CHALLENGING
rubric={accuracy:5}

**Warning: This exercise is challenging and could be time-consuming. Please only attempt if you find yourself finishing the assignment early and you want a bit more of a challenge.**

### Joins to answer a question!

In the {canlang} package there are two separate data sets (`region_lang` and `region_data`) that would be useful to join together to answer such statistical questions what are the top 10 regions in Canada which report a given language as their mother tongue, measured by the percentage of people in that region who claim that language as their mother tongue. 

Your task here for this **challenging** question is to choose a language and a language metric (e.g., `mother_tongue`, `most_at_home`, `most_at_work`, `lang_known`) you are interested in, and create such a table. You must write your question of interest in 1-2 sentences of written English, as well as explain your results in 1-2 sentences in written English to obtain full marks.

_Type your answer here, replacing this text._

```{r tags=c()}

```

Congratulations! You are done the lab!!! Pat yourself on the back, and submit your lab to **GitHub** and Gradescope! Make sure you have 3 Git commits!
